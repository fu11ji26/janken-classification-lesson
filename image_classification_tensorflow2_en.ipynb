{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17cjdD-gGSxpp0noGAckhw1FGcE1J6Kmz","timestamp":1679211753483}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/karaage0703/karaage-ai-book/blob/master/ch02/02_karaage_ai_book_image_classification_tf2_x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"DtU8eIsOsNcv"},"source":["# Image Classification by deep-learning (AI)\n","\n","This is an exercise to practice Image Classification of Janken (Rock-Paper-Scissors) hand shape."]},{"cell_type":"markdown","metadata":{"id":"qNgUsGFZBLEh"},"source":["## Download Training Data\n","\n","Download (Clone) the \"Janken\" Training data from GitHub."]},{"cell_type":"code","metadata":{"id":"Qtkx-d0RWnZN"},"source":["!git clone https://github.com/fu11ji26/janken_dataset datasets\n","!rm -rf datasets/.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hKLAhGSCufr"},"source":["Check the contents of data and display the image of hand shape, \"gu\"(=Rock), \"choki\" (=Scissors) or \"pa\"(=Paper)."]},{"cell_type":"code","metadata":{"id":"HdO2sCkkGXU6"},"source":["# !ls datasets/gu\n","!ls datasets/choki\n","# !ls datasets/pa"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63s1idu3Ct_Q"},"source":["from IPython.display import Image as IPImage\n","from IPython.display import display_jpeg\n","display_jpeg(IPImage('datasets/choki/IMG_0770.JPG'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWdaU-dW4kvI"},"source":["## Split the original training data into Training Data and Validation Data."]},{"cell_type":"markdown","metadata":{"id":"JPVitbmqrXgi"},"source":["Visualize the folder structure with a software called **tree**."]},{"cell_type":"code","metadata":{"id":"dA0Me7ARH3gJ"},"source":["!sudo apt install tree\n","!tree -d datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zmdetFKFvWp"},"source":["Make an original data sets folder and a target folder.\n","\n","The target folder consists of the training data sets and validation data sets."]},{"cell_type":"code","metadata":{"id":"ZA4SGY54GY6b"},"source":["dataset_original_dir = 'datasets'\n","dataset_root_dir = 'target_datasets'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kevX13wW47Ub"},"source":["Split the target datasets into training and validation data.\n","\n","The ratio of training data to validation data is specified by \"train_size\" which default value is 0.8."]},{"cell_type":"code","metadata":{"id":"eGSRbbuIreaQ"},"source":["!wget \"https://raw.githubusercontent.com/fu11ji26/janken-classification-lesson/master/split_train_val.py\" -O \"split_train_val.py\"\n","import split_train_val\n","split_train_val.image_dir_train_val_split(dataset_original_dir, dataset_root_dir, train_size=0.8)\n","train_dir = 'target_datasets/train'\n","val_dir = 'target_datasets/val'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize the folder structure and check the contens of data."],"metadata":{"id":"i7bfzQ63e76Y"}},{"cell_type":"code","metadata":{"id":"zHugFL3VIJfb"},"source":["!tree -d target_datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVNXMfrLD97Y"},"source":["!ls target_datasets/train/choki"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3-W-iIAEDXc"},"source":["!ls target_datasets/val/choki"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"roHDM7MB1w9S"},"source":["## Create a label files\n","Label names are choki, gu and pa."]},{"cell_type":"markdown","metadata":{"id":"VSq7-H5b2DVx"},"source":["学習するファイルのラベルを作成します"]},{"cell_type":"markdown","metadata":{"id":"UN5gSnfyz7Tp"},"source":["First, import the required libraries.\n","\n","Then, specify the back-up folder to save the data.\n","\n","Third, create the label data.\n","\n","Last, display the class number which is the number of images (= gu, choki, pa).\n"]},{"cell_type":"code","metadata":{"id":"ZRQkx3zp1Pwt"},"source":["import sys\n","import os\n","import shutil\n","backup_dir = './model'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRk9ZAWZlj9C"},"source":["labels = [d for d in os.listdir(dataset_original_dir) \\\n","    if os.path.isdir(os.path.join(dataset_original_dir, d))]\n","labels.sort()\n","\n","if os.path.exists(backup_dir):\n","  shutil.rmtree(backup_dir)\n","\n","os.makedirs(backup_dir)\n","\n","with open(backup_dir + '/labels.txt','w') as f:\n","  for label in labels:\n","    f.write(label+\"\\n\")\n","\n","NUM_CLASSES = len(labels)\n","print(\"class number=\" + str(NUM_CLASSES))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CzE-lgUNJ3e8"},"source":["Check the labels. If the label names (choki, gu, pa) are lined up, it is OK."]},{"cell_type":"code","metadata":{"id":"ZRBOzF1i6HnT"},"source":["!cat ./model/labels.txt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fLcN1JHv2Q6g"},"source":["## Set up the learning"]},{"cell_type":"markdown","metadata":{"id":"ln1wU_8DFe22"},"source":["Import the necessary libraries.\n","\n","Google colaboratory works with \"TensorFlow 2.x\" series, so select the version 2."]},{"cell_type":"code","metadata":{"id":"cvUS5Z5CEjQp"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qwz5rPa333ch"},"source":["Load label information from the label files created ahead."]},{"cell_type":"code","metadata":{"id":"BkbhFC1Dxrb-"},"source":["labels = []\n","with open(backup_dir + '/labels.txt','r') as f:\n","  for line in f:\n","    labels.append(line.rstrip())\n","print(labels)\n","\n","NUM_CLASSES = len(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WyuTS7gwyVP0"},"source":["### Set hyper-parameters for learning"]},{"cell_type":"code","metadata":{"id":"jBSQYa3QE9jQ"},"source":["# Learning rate\n","LEARNING_RATE = 0.001\n","# Epoch (number of generations)\n","EPOCHS = 20\n","# batch size\n","BATCH_SIZE = 8"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zRKlr-AcTVEn"},"source":["### Pre-process (transform) the data set"]},{"cell_type":"code","metadata":{"id":"BP3ogIEXGQzf"},"source":["IMAGE_SIZE = 64\n","\n","train_data_gen = ImageDataGenerator(rescale=1./255)\n","val_data_gen = ImageDataGenerator(rescale=1./255)\n","\n","train_data = train_data_gen.flow_from_directory(\n","    train_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    color_mode='rgb', batch_size=BATCH_SIZE,\n","    class_mode='categorical', shuffle=True)\n","\n","validation_data = val_data_gen.flow_from_directory(\n","    val_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    color_mode='rgb', batch_size=BATCH_SIZE,\n","    class_mode='categorical', shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XkrwuMQOykJO"},"source":["### Check training data and labels of learning for one unit (batch) size"]},{"cell_type":"code","metadata":{"id":"M6OJHTv_8BB6"},"source":["(image_data,label_data) = train_data.next()\n","print(image_data)\n","print(label_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Size of training data and labels for one unit"],"metadata":{"id":"7xt29r80o1lR"}},{"cell_type":"code","metadata":{"id":"N-QJyJme-YgW"},"source":["print(image_data.shape)\n","print(label_data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yNNJhWyCrHW"},"source":["import matplotlib.pyplot as plt\n","image_numb = 3 # Specify 3 or 6\n","for i in range(0, image_numb):\n","  ax = plt.subplot(image_numb // 3, 3, i + 1)\n","  plt.tight_layout()\n","  ax.set_title(str(i))\n","  plt.imshow(image_data[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeYkR1giyql0"},"source":["## Creating AI Models\n","Create a convolutional neural network (CNN) model."]},{"cell_type":"code","metadata":{"id":"2W57_jd8K8Ox"},"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding='same',\n","    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(128))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(NUM_CLASSES))\n","model.add(Activation('softmax'))\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","#opt = tf.keras.optimizers.SGD(lr=LEARNING_RATE)\n","\n","model.compile(opt, loss='categorical_crossentropy', \n","    metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"01E8ayYiGL9T"},"source":["Review the model overview.\n","\n","The total number of parameters in the network is about 8 million."]},{"cell_type":"code","metadata":{"id":"5pAr9iyrGNWI"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqLJDFl3rznt"},"source":["Performs AI model training."]},{"cell_type":"code","metadata":{"id":"GxzfODkyl5hN"},"source":["%%time\n","history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELuHBiwnGIk7"},"source":["## Visualization of learning results\n","Check the \"loss\" (value of the error function).\n","\n","The lower the loss, the better the performance."]},{"cell_type":"code","metadata":{"id":"5Oz6q5XnQGEW"},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Training and validation loss')\n","plt.ylabel('loss')\n","plt.xlim([0.0, EPOCHS])\n","plt.xlabel('epoch')\n","plt.legend(['loss', 'val_loss'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5SFJtbPg5Hd7"},"source":["Check the accuracy.\n","\n","\"acc\" is accuracy for training data.\n","\n","For example, \"acc = 0.8\" means 80% correct.\n","\n","The so-called true accuracy is \"val_acc\" which is accuracy for validation (non-trained) data."]},{"cell_type":"code","metadata":{"id":"8nKjkoxfG7Ox"},"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Training and validation accuracy')\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.xlim([0.0, EPOCHS])\n","plt.ylim([0.0, 1.0])\n","plt.legend(['acc', 'val_acc'], loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vWiax4zg70l"},"source":["## Estimate the hand shape of validation (non-trained) data"]},{"cell_type":"code","metadata":{"id":"Fy5DOL0JUQar"},"source":["# Get the ordered list of class names:\n","import PIL.Image as Image\n","class_names = validation_data.class_indices.items()\n","class_names = np.array([key.title() for key, value in class_names])\n","\n","validation_data.reset()\n","validation_data.shuffle = True\n","validation_data.batch_size = BATCH_SIZE\n","\n","# Retrieve the first batch from the validation data\n","for validation_image_batch, validation_label_batch in validation_data:\n","  break\n","\n","validation_id = np.argmax(validation_label_batch, axis=-1)\n","validation_label = class_names[validation_id]\n","predicted_batch = model.predict(validation_image_batch)\n","\n","# Returns the indices of the maximum values along a given axis\n","predicted_id = np.argmax(predicted_batch, axis=-1)\n","\n","# Return the maximum values along a given axis\n","predicted_score = np.max(predicted_batch, axis=-1)\n","\n","predicted_label_batch = class_names[predicted_id]\n","\n","plt.figure(figsize=(16, 9))\n","plt.subplots_adjust(hspace=0.5)\n","\n","# Display the classification results for the first 30 images\n","for n in range(min(validation_image_batch.shape[0], 30)):\n","  plt.subplot(6, 5, n + 1)\n","\n","  # Convert the range from -1 to 1 to the range from 0 to 1\n","  plt.imshow(np.array(validation_image_batch[n]*255,np.int32))\n","  color = 'green' if predicted_id[n] == validation_id[n] else 'red'\n","  predicted_label = predicted_label_batch[n].title()\n","  plt.title(predicted_label + ' ({:.2f}, {})'.format(\n","      predicted_score[n], validation_label[n]), color=color)\n","  plt.axis('off')\n","\n","_ = plt.suptitle('Model predictions (green: correct, red: incorrect)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Displays the results of evaluating the performance of the AI model by Confusion Matrix.\n","\n","Confusion Matrix represents the ratio of the model's predicted result to the correct answers."],"metadata":{"id":"FkviPZUtEV0w"}},{"cell_type":"code","metadata":{"id":"S7h85uRoRODs"},"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","validation_data.reset()\n","validation_data.shuffle =  False\n","validation_data.batch_size = 1\n","\n","# Retrieve the first batch from the validation data\n","for validation_image_batch, validation_label_batch in validation_data:\n","  break\n","\n","predicted = model.predict(validation_data, steps=validation_data.n)\n","predicted_classes = np.argmax(predicted, axis=-1)\n","\n","# Apply normalization\n","# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","cm = confusion_matrix(validation_data.classes, predicted_classes)\n","cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","plt.figure(figsize=(12, 9))\n","\n","# https://seaborn.pydata.org/generated/seaborn.heatmap.html\n","# https://matplotlib.org/users/colormaps.html\n","sns.heatmap(cm, annot=True, square=True, cmap=plt.cm.Blues,\n","            xticklabels=validation_data.class_indices,\n","            yticklabels=validation_data.class_indices)\n","\n","plt.title(\"Confusion Matrix\")\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.xlim([0.0, 3.0])\n","plt.ylim([0.0, 3.0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3jKFzqu-00L"},"source":["## Summary\n"]},{"cell_type":"markdown","metadata":{"id":"W-BVvtN2aqKX"},"source":["At this point, the lesson of steps from data preparation, training and  estimation is complete.\n","\n","Let's change the hyper-parameters and see what happens to change in results of learning."]},{"cell_type":"markdown","metadata":{"id":"F7UIdrA1KFlO"},"source":["## References (almost in Japanese)\n","\n","Structures of Convolutional Newral Network\n","- http://aidiary.hatenablog.com/entry/20161127/1480240182\n","\n","Data Augmentation\n","- https://github.com/bohemian916/deeplearning_tool/blob/master/increase_picture.py\n","\n","GradCam\n","- https://github.com/shinmura0/Python-study-group/blob/master/Text3.ipynb\n","\n","GradCam Confusion Matrix\n","- https://colab.research.google.com/drive/1mirG8BSoB3k87mh-qyY3-8-ZXj0XB6h6\n","\n","Support for TensorFlow 2.x\n","- http://tensorflow.classcat.com/2019/11/04/tf20-tutorials-images-classification/\n","\n","Fixing random numbers (Seeds)\n","- https://scrapbox.io/nwtgck/Tensorflow+Keras%E3%81%A7%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E3%81%82%E3%82%8B%E4%B9%B1%E6%95%B0%E3%82%92%E7%94%9F%E6%88%90%E3%81%99%E3%82%8B_-_%E3%82%B7%E3%83%BC%E3%83%89%E5%9B%BA%E5%AE%9A\n","- https://qiita.com/okotaku/items/8d682a11d8f2370684c9\n","\n","\n","Other Related Information\n","- http://aidiary.hatenablog.com/entry/20161212/1481549365\n","- https://qiita.com/yampy/items/706d44417c433e68db0d\n","- https://qiita.com/haru1977/items/17833e508fe07c004119\n","- http://hatakazu.hatenablog.com/entry/2017/06/08/045953\n","- https://qiita.com/Mco7777/items/2b76aba1bae35f2623ea\n","\n"]}]}